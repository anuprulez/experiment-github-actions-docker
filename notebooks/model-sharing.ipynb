{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c319cf4",
   "metadata": {},
   "source": [
    "## Sharing machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd97a83",
   "metadata": {},
   "source": [
    "### Save and retrieve Scikit-learn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38e4bf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a model.\n",
    "import os\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "clr = RandomForestClassifier()\n",
    "clr.fit(X_train, y_train)\n",
    "\n",
    "# accuracy on test data with trained model\n",
    "clr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fa84fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into ONNX format\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "initial_type = [('float_input', FloatTensorType([None, 4]))]\n",
    "onx = convert_sklearn(clr, initial_types=initial_type)\n",
    "\n",
    "if not os.path.exists('sklearn_model'):\n",
    "    os.makedirs('sklearn_model')\n",
    "\n",
    "# save trained model\n",
    "with open(\"sklearn_model/rf_iris.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdd89024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the prediction with ONNX Runtime\n",
    "import onnxruntime as rt\n",
    "import numpy\n",
    "\n",
    "# retrieve trained model\n",
    "sess = rt.InferenceSession(\"sklearn_model/rf_iris.onnx\")\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "\n",
    "# predict labels of test data\n",
    "pred_onx = sess.run([label_name], {input_name: X_test.astype(numpy.float32)})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8731edb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 2, 0, 1, 1, 2, 1, 1, 2, 2, 0, 0, 2,\n",
       "       2, 1, 2, 0, 2, 0, 2, 0, 1, 2, 2, 2, 2, 2, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_onx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b54ba55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics as score\n",
    "\n",
    "# accuracy on test data using retrieved model\n",
    "score.accuracy_score(y_test, pred_onx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2e7427",
   "metadata": {},
   "source": [
    "## Save Tensorflow model as ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "665c515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "import tf2onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfba32e0-685a-4062-91e3-d7b9320b85d1",
   "metadata": {},
   "source": [
    "#### Set memory limit of GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9b89e10-6c9d-4736-8526-d86addf3cace",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = tf.config.list_physical_devices('GPU')\n",
    "if gpu:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpu[0], True)\n",
    "        tf.config.set_logical_device_configuration(gpu[0], [tf.config.LogicalDeviceConfiguration(memory_limit=5000)])\n",
    "    except Exception as e:\n",
    "        print(\"Error: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5c84eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://www.tensorflow.org/tutorials/quickstart/advanced\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Add a channels dimension\n",
    "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
    "x_test = x_test[..., tf.newaxis].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95ef4bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b5943a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(128, activation='relu')\n",
    "        self.d2 = Dense(10)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e15d08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a90c75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9b9711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    # training=True is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(images, training=True)\n",
    "    loss = loss_object(labels, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(labels, predictions)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  predictions = model(images, training=False)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b114a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.12775836884975433, Accuracy: 96.18000030517578, Test Loss: 0.062898188829422, Test Accuracy: 97.91999816894531\n",
      "Epoch 2, Loss: 0.04118673875927925, Accuracy: 98.7066650390625, Test Loss: 0.051221318542957306, Test Accuracy: 98.22000122070312\n",
      "Epoch 3, Loss: 0.02161228656768799, Accuracy: 99.29999542236328, Test Loss: 0.06005851924419403, Test Accuracy: 98.27999877929688\n",
      "Epoch 4, Loss: 0.012819205410778522, Accuracy: 99.55999755859375, Test Loss: 0.05241604894399643, Test Accuracy: 98.55999755859375\n",
      "Epoch 5, Loss: 0.010816505178809166, Accuracy: 99.6383285522461, Test Loss: 0.07686861604452133, Test Accuracy: 98.08999633789062\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  \n",
    "  test_loss.reset_states()\n",
    "  test_accuracy.reset_states()\n",
    "\n",
    "  for images, labels in train_ds:\n",
    "    train_step(images, labels)\n",
    "\n",
    "  for test_images, test_labels in test_ds:\n",
    "    test_step(test_images, test_labels)\n",
    "\n",
    "  print(\n",
    "    f'Epoch {epoch + 1}, '\n",
    "    f'Loss: {train_loss.result()}, '\n",
    "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "    f'Test Loss: {test_loss.result()}, '\n",
    "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8daf0374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
      "INFO:tensorflow:Assets written to: tf_model/assets\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('tf_model'):\n",
    "    os.makedirs('tf_model')\n",
    "\n",
    "if not os.path.exists('onnx_loaded_model'):\n",
    "    os.makedirs('onnx_loaded_model')\n",
    "\n",
    "tf.saved_model.save(model, 'tf_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "628cfb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2021-06-28 06:04:47,565 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2021-06-28 06:04:48,356 - INFO - Signatures found in model: [serving_default].\n",
      "2021-06-28 06:04:48,357 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
      "2021-06-28 06:04:48,357 - INFO - Output names: ['output_1']\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.9/site-packages/tf2onnx/tf_loader.py:603: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-06-28 06:04:50,353 - WARNING - From /opt/conda/lib/python3.9/site-packages/tf2onnx/tf_loader.py:603: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-06-28 06:04:51,947 - INFO - Using tensorflow=2.5.0, onnx=1.9.0, tf2onnx=1.8.5/50049d\n",
      "2021-06-28 06:04:51,947 - INFO - Using opset <onnx, 7>\n",
      "2021-06-28 06:04:52,658 - INFO - Computed 0 values for constant folding\n",
      "2021-06-28 06:04:54,690 - INFO - Optimizing ONNX model\n",
      "2021-06-28 06:04:56,742 - INFO - After optimization: Cast -1 (1->0), Const +1 (7->8), Identity -5 (5->0), Reshape +1 (1->2), Transpose -1 (2->1)\n",
      "2021-06-28 06:04:57,193 - INFO - \n",
      "2021-06-28 06:04:57,193 - INFO - Successfully converted TensorFlow model tf_model to ONNX\n",
      "2021-06-28 06:04:57,193 - INFO - Model inputs: ['input_1:0', 'new_shape__12', 'const_fold_opt__13', 'StatefulPartitionedCall/my_model/dense_1/MatMul/ReadVariableOp:0', 'StatefulPartitionedCall/my_model/dense_1/BiasAdd/ReadVariableOp:0', 'StatefulPartitionedCall/my_model/dense/MatMul/ReadVariableOp:0', 'StatefulPartitionedCall/my_model/dense/BiasAdd/ReadVariableOp:0', 'StatefulPartitionedCall/my_model/conv2d/Conv2D/ReadVariableOp:0', 'StatefulPartitionedCall/my_model/conv2d/BiasAdd/ReadVariableOp:0']\n",
      "2021-06-28 06:04:57,193 - INFO - Model outputs: ['output_1']\n",
      "2021-06-28 06:04:57,194 - INFO - ONNX model is saved at onnx_loaded_model/mnist_model.onnx\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python -m tf2onnx.convert --saved-model tf_model --output onnx_loaded_model/mnist_model.onnx --opset 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4079c4d",
   "metadata": {},
   "source": [
    "## Retrieve ONNX model as Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fff713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa90f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = onnx.load(\"onnx_loaded_model/mnist_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c97d9dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_loaded_model = prepare(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f54225ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Mean test loss: 0.07686860859394073\n",
      "Mean test accuracy: 98.09304809570312\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "total_test_accuracy = []\n",
    "total_test_loss = []\n",
    "\n",
    "def predict_test(images, labels):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "  test_loss.reset_states()\n",
    "  test_accuracy.reset_states()\n",
    "  true_labels = []\n",
    "  predicted_labels = []\n",
    "  for i, item in enumerate(images):\n",
    "      prediction = tf_loaded_model.run(item, training=False)\n",
    "      pred = np.array(prediction).squeeze()\n",
    "      true_labels.append([labels[i].numpy()])\n",
    "      predicted_labels.append(pred)\n",
    "  t_loss = loss_object(true_labels, predicted_labels)  \n",
    "  return test_loss(t_loss), test_accuracy(labels, predicted_labels)\n",
    "\n",
    "\n",
    "for test_images, test_labels in test_ds:\n",
    "  ls, acc = predict_test(test_images, test_labels)\n",
    "  loss = test_loss.result()\n",
    "  accuracy = test_accuracy.result() * 100\n",
    "  total_test_accuracy.append(accuracy.numpy())\n",
    "  total_test_loss.append(loss.numpy())\n",
    "\n",
    "print(\"Mean test loss: {}\".format(np.mean(total_test_loss)))\n",
    "print(\"Mean test accuracy: {}\".format(np.mean(total_test_accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d174b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a071e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8e3a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d67fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6ec990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21047224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
